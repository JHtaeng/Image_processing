{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy.linalg as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 기초\n",
    "\n",
    "- inverve를 통한 mnist 학습\n",
    "- 신경망을 통한 mnist 학습\n",
    "- CNN 통한 mnist 학습\n",
    "- fashion mnist, face db 테스트\n",
    "- web 연동 (한글, 스케치 인식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1249d806948>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "plt.imshow(X_train[2], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124997f6388>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "plt.imshow(X_test[2], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38 254\n",
      "  109   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  87 252\n",
      "   82   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 135 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 244 150\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  84 254  63\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 202 223  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  32 254 216   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  95 254 195   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 140 254  77   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  57 237 205   8   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 124 255 165   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 171 254  81   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  24 232 215   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 120 254 159   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 151 254 142   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 228 254  66   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  61 251 254  66   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 141 254 205   3   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  10 215 254 121   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5 198 176  10   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "(60000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(X_test[2])\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],784))\n",
    "X_test = X_test.reshape((X_test.shape[0],784))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e = to_categorical(y_train)\n",
    "y_test_e = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 역행렬을 이용한 MNIST 학습\n",
    "\n",
    "   y = Wx + b\n",
    "\n",
    "1. y = W * [x 1] -> [x 1] * W\n",
    "    - A -> 60000x785(784+1) 행렬\n",
    "    - 1은 y = Wx + b에서 상수 b\n",
    "    - Y -> 60000x10 행렬\n",
    "2. W = inv(A) * Y  \n",
    "   - W -> 785x10 행렬\n",
    "3. predict = [x 1] * W\n",
    "    - x = 1x784\n",
    "    - W = 785x10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n"
     ]
    }
   ],
   "source": [
    "A = np.hstack((X_train, np.ones((60000,1))))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 10)\n",
      "[[ 7.44778176e-17  3.08116485e-17  6.24517735e-17 ... -1.88247216e-17\n",
      "  -9.68761668e-17  2.74183832e-17]\n",
      " [-2.02652642e-15 -8.88043361e-15 -1.23469953e-14 ...  9.01778765e-15\n",
      "   1.44453949e-14  4.97795720e-15]\n",
      " [ 3.89572462e-15  8.31633536e-15  8.79628286e-15 ... -6.90318037e-15\n",
      "  -1.11422250e-14 -2.33884532e-15]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.57799659e-01  2.41326501e-01  4.98284745e-02 ...  1.41540555e-01\n",
      "  -1.23002061e-01  4.55121243e-02]]\n",
      "(785,)\n",
      "Wall time: 9.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "W=np.matmul(lin.pinv(A), y_train_e)\n",
    "print(W.shape)\n",
    "print(W)\n",
    "print(W[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1249fc35ec8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test 데이터로 예측\n",
    "T = np.hstack((X_test, np.ones((10000,1))))\n",
    "p_ =np.matmul(T, W)\n",
    "print(p_.shape)\n",
    "\n",
    "p = np.argmax(p_,axis=1)\n",
    "print(p.shape)\n",
    "print(p)\n",
    "\n",
    "plt.imshow(X_test[9999,:].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인식률\n",
    "np.mean(p==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[2 2 2]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],\n",
    "              [7,8,9],\n",
    "              [4,5,6]])\n",
    "print(np.argmax(a)) # 가장 큰값을 갖는 곳의 인덱스 \n",
    "print(np.argmax(a, axis=1)) # 각 행에서 가장 큰 값을 갖는 곳 인덱스 \n",
    "print(np.argmax(a, axis=0)) # 각 열에서 가장 큰 값을 갖는 곳 인덱스 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 신경망을 통한 MNIST 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 9.7959 - accuracy: 0.8396\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.9115 - accuracy: 0.8809\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6551 - accuracy: 0.8823\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.6154 - accuracy: 0.8840\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2871 - accuracy: 0.8883\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.3310 - accuracy: 0.8876\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.3427 - accuracy: 0.8861\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2069 - accuracy: 0.8894\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.3156 - accuracy: 0.8885\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 5.2377 - accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 10,\n",
    "                verbose = 1,\n",
    "                batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 6.534481048583984\n",
      "Test accuracy: 0.8790000081062317\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000,)\n",
      "[7 2 1 ... 9 5 6]\n",
      "0.879\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test)\n",
    "print(p.shape)\n",
    "\n",
    "p = np.argmax(p, axis=1)\n",
    "print(p.shape)\n",
    "print(p)\n",
    "print(np.mean(p==y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input size * 뉴런 수 + 뉴런수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "# 784 차원 + 1 \n",
    "# 분류기 = 785*10 = 7850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                60        \n",
      "=================================================================\n",
      "Total params: 3,985\n",
      "Trainable params: 3,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=784, activation='relu')) # layer1 = 784*5+5\n",
    "model.add(Dense(10, activation = 'softmax')) # layer2 = 5*10+10\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.7812 - accuracy: 0.3235\n",
      "Epoch 2/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6949 - accuracy: 0.3505\n",
      "Epoch 3/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.6391 - accuracy: 0.3645\n",
      "Epoch 4/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5910 - accuracy: 0.3758\n",
      "Epoch 5/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5698 - accuracy: 0.3776\n",
      "Epoch 6/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5432 - accuracy: 0.3892\n",
      "Epoch 7/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5280 - accuracy: 0.3973\n",
      "Epoch 8/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.5039 - accuracy: 0.4018\n",
      "Epoch 9/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.4708 - accuracy: 0.4196\n",
      "Epoch 10/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.3805 - accuracy: 0.4762\n",
      "Epoch 11/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.2439 - accuracy: 0.5439\n",
      "Epoch 12/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.1897 - accuracy: 0.5669\n",
      "Epoch 13/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.1597 - accuracy: 0.5788\n",
      "Epoch 14/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.1432 - accuracy: 0.5895\n",
      "Epoch 15/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.1282 - accuracy: 0.6001\n",
      "Epoch 16/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.1136 - accuracy: 0.6093\n",
      "Epoch 17/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0882 - accuracy: 0.6274\n",
      "Epoch 18/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0764 - accuracy: 0.6352\n",
      "Epoch 19/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0684 - accuracy: 0.6400\n",
      "Epoch 20/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0681 - accuracy: 0.6392\n",
      "Epoch 21/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0633 - accuracy: 0.6413\n",
      "Epoch 22/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0611 - accuracy: 0.6417\n",
      "Epoch 23/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0632 - accuracy: 0.6410\n",
      "Epoch 24/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0567 - accuracy: 0.6460\n",
      "Epoch 25/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0568 - accuracy: 0.6431\n",
      "Epoch 26/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0531 - accuracy: 0.6440\n",
      "Epoch 27/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0538 - accuracy: 0.6453\n",
      "Epoch 28/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0519 - accuracy: 0.6460\n",
      "Epoch 29/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0544 - accuracy: 0.6434\n",
      "Epoch 30/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0495 - accuracy: 0.6456\n",
      "Epoch 31/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0499 - accuracy: 0.6470\n",
      "Epoch 32/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0468 - accuracy: 0.6478\n",
      "Epoch 33/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0448 - accuracy: 0.6474\n",
      "Epoch 34/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0437 - accuracy: 0.6485\n",
      "Epoch 35/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0425 - accuracy: 0.6491\n",
      "Epoch 36/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0411 - accuracy: 0.6500\n",
      "Epoch 37/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0414 - accuracy: 0.6491\n",
      "Epoch 38/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0398 - accuracy: 0.6484\n",
      "Epoch 39/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0422 - accuracy: 0.6494\n",
      "Epoch 40/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0374 - accuracy: 0.6512\n",
      "Epoch 41/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0404 - accuracy: 0.6493\n",
      "Epoch 42/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0363 - accuracy: 0.6513\n",
      "Epoch 43/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0387 - accuracy: 0.6493\n",
      "Epoch 44/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0390 - accuracy: 0.6486\n",
      "Epoch 45/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0371 - accuracy: 0.6482\n",
      "Epoch 46/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0384 - accuracy: 0.6480\n",
      "Epoch 47/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0375 - accuracy: 0.6494\n",
      "Epoch 48/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0364 - accuracy: 0.6509\n",
      "Epoch 49/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0397 - accuracy: 0.6467\n",
      "Epoch 50/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0362 - accuracy: 0.6504\n",
      "Epoch 51/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0328 - accuracy: 0.6517\n",
      "Epoch 52/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0345 - accuracy: 0.6506\n",
      "Epoch 53/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0358 - accuracy: 0.6500\n",
      "Epoch 54/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0394 - accuracy: 0.6483\n",
      "Epoch 55/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0358 - accuracy: 0.6488\n",
      "Epoch 56/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0340 - accuracy: 0.6495\n",
      "Epoch 57/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0339 - accuracy: 0.6497\n",
      "Epoch 58/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0377 - accuracy: 0.6470\n",
      "Epoch 59/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0353 - accuracy: 0.6506\n",
      "Epoch 60/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0356 - accuracy: 0.6488\n",
      "Epoch 61/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0363 - accuracy: 0.6499\n",
      "Epoch 62/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0389 - accuracy: 0.6488\n",
      "Epoch 63/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0330 - accuracy: 0.6504\n",
      "Epoch 64/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0353 - accuracy: 0.6496\n",
      "Epoch 65/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0336 - accuracy: 0.6492\n",
      "Epoch 66/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0331 - accuracy: 0.6517\n",
      "Epoch 67/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0362 - accuracy: 0.6502\n",
      "Epoch 68/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0311 - accuracy: 0.6515\n",
      "Epoch 69/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0318 - accuracy: 0.6505\n",
      "Epoch 70/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0371 - accuracy: 0.6474\n",
      "Epoch 71/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0354 - accuracy: 0.6481\n",
      "Epoch 72/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0328 - accuracy: 0.6498\n",
      "Epoch 73/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0376 - accuracy: 0.6487\n",
      "Epoch 74/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0338 - accuracy: 0.6496\n",
      "Epoch 75/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0308 - accuracy: 0.6508\n",
      "Epoch 76/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0347 - accuracy: 0.6481\n",
      "Epoch 77/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0301 - accuracy: 0.6535\n",
      "Epoch 78/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0308 - accuracy: 0.6531\n",
      "Epoch 79/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0344 - accuracy: 0.6496\n",
      "Epoch 80/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0356 - accuracy: 0.6487\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0299 - accuracy: 0.6496\n",
      "Epoch 82/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0337 - accuracy: 0.6503\n",
      "Epoch 83/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0326 - accuracy: 0.6500\n",
      "Epoch 84/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0309 - accuracy: 0.6523\n",
      "Epoch 85/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0319 - accuracy: 0.6503\n",
      "Epoch 86/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0279 - accuracy: 0.6511\n",
      "Epoch 87/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0319 - accuracy: 0.6499\n",
      "Epoch 88/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0283 - accuracy: 0.6523\n",
      "Epoch 89/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0359 - accuracy: 0.6473\n",
      "Epoch 90/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0301 - accuracy: 0.6502\n",
      "Epoch 91/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0288 - accuracy: 0.6507\n",
      "Epoch 92/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0295 - accuracy: 0.6512\n",
      "Epoch 93/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0288 - accuracy: 0.6546\n",
      "Epoch 94/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0320 - accuracy: 0.6487\n",
      "Epoch 95/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0256 - accuracy: 0.6548\n",
      "Epoch 96/100\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 1.0272 - accuracy: 0.6538\n",
      "Epoch 97/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0263 - accuracy: 0.6536\n",
      "Epoch 98/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0297 - accuracy: 0.6520\n",
      "Epoch 99/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0300 - accuracy: 0.6510\n",
      "Epoch 100/100\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 1.0306 - accuracy: 0.6518\n",
      "Test loss: 1.045938491821289\n",
      "Test accuracy: 0.6606000065803528\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 100,\n",
    "                verbose = 1,\n",
    "                batch_size=100)\n",
    "\n",
    "score = model.evaluate(X_test, y_test_e, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, activation='relu')) \n",
    "model.add(Dense(128, activation = 'relu')) \n",
    "model.add(Dense(10, activation = 'softmax')) \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics = ['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 2.2974 - accuracy: 0.8855\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.3261 - accuracy: 0.9400\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.1833 - accuracy: 0.9572\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.1284 - accuracy: 0.9666\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.1081 - accuracy: 0.9707\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0984 - accuracy: 0.9729\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0988 - accuracy: 0.9732\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0889 - accuracy: 0.9754\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9779\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0722 - accuracy: 0.9793\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0752 - accuracy: 0.9792\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0694 - accuracy: 0.9809\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0617 - accuracy: 0.9822\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0600 - accuracy: 0.9828\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0512 - accuracy: 0.9850\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0551 - accuracy: 0.9843\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0464 - accuracy: 0.9866\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0511 - accuracy: 0.9861\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0447 - accuracy: 0.9874\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0461 - accuracy: 0.9871\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.9879\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0457 - accuracy: 0.9872\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0364 - accuracy: 0.9896\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0437 - accuracy: 0.9886\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0363 - accuracy: 0.9906\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9912\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0384 - accuracy: 0.9904\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0290 - accuracy: 0.9923\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0367 - accuracy: 0.9910\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0315 - accuracy: 0.9919\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0311 - accuracy: 0.9923\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0255 - accuracy: 0.9935\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9918\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.9937\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0284 - accuracy: 0.9936\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0295 - accuracy: 0.9934\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0333 - accuracy: 0.9926\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0312 - accuracy: 0.9933\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0294 - accuracy: 0.9933\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0278 - accuracy: 0.9937\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0303 - accuracy: 0.9935\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0307 - accuracy: 0.9932\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0229 - accuracy: 0.9949\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0262 - accuracy: 0.9944\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0243 - accuracy: 0.9950\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0242 - accuracy: 0.9948\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0247 - accuracy: 0.9948\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0213 - accuracy: 0.9955\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0228 - accuracy: 0.9952\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0335 - accuracy: 0.9938\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 50,\n",
    "                verbose = 1,\n",
    "                batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.32570669054985046\n",
      "Test accuracy: 0.9707000255584717\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.1442 - accuracy: 0.9518\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0102 - accuracy: 0.9978\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0050 - accuracy: 0.9991\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0043 - accuracy: 0.9984\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0043 - accuracy: 0.9985\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 0.0049 - accuracy: 0.9983\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 3.2403e-04 - accuracy: 0.9999\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 9.4799e-05 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.2455e-05 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 1.2930e-05 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 9.4221e-06 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 7.1913e-06 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 5.5262e-06 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 4.2951e-06 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 3.3377e-06 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.5648e-06 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.0079e-06 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.5396e-06 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.1975e-06 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 9.0212e-07 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 6.9747e-07 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 5.3823e-07 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 4.0988e-07 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 3.2031e-07 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 3s 5ms/step - loss: 2.3605e-07 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.8142e-07 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.4506e-07 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 1.0500e-07 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 8.0452e-08 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 6.4703e-08 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 4.8091e-08 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 3.7158e-08 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9981\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0104 - accuracy: 0.9967\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                epochs = 50,\n",
    "                verbose = 1,\n",
    "                batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12981492280960083\n",
      "Test accuracy: 0.9818000197410583\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape((60000,28,28,1))\n",
    "X_test = X_test.reshape((10000,28,28,1))\n",
    "y_train_e = to_categorical(y_train)\n",
    "y_test_e = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(28,28,1), filters = 50, kernel_size= (3,3), \n",
    "                strides = (1,1), padding = 'same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu')) \n",
    "model.add(Dense(10, activation = 'softmax')) \n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer =adam, \n",
    "              metrics = ['accuracy']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9800)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               2509056   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,512,126\n",
      "Trainable params: 2,512,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() \n",
    "\n",
    "# input -> 60000 x 28 x 28 x 1\n",
    "# layer -> ?, 28 x 28 x 50            500 = 3 x 3 x 50 + 50\n",
    "# dense layer -> 9800*256 + 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(28,28,1), filters = 50, kernel_size= (3,3), \n",
    "                strides = (1,1), padding = 'same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters = 30, kernel_size= (3,3), \n",
    "                strides = (1,1), padding = 'same')) \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu')) \n",
    "model.add(Dense(10, activation = 'softmax')) \n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer =adam, \n",
    "              metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 30)        13530     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1470)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               376576    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 393,176\n",
      "Trainable params: 393,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() \n",
    "\n",
    "# layer conv1 - > 3 * 3 * 1 * 50 + 50 = 500\n",
    "#layer conv2 -> 3 * 3 * 50 * 30 + 30 = 13530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "480/480 [==============================] - 34s 70ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0423 - val_accuracy: 0.9893\n",
      "Epoch 2/5\n",
      "480/480 [==============================] - 34s 71ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0358 - val_accuracy: 0.9898\n",
      "Epoch 3/5\n",
      "480/480 [==============================] - 34s 71ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0413 - val_accuracy: 0.9893\n",
      "Epoch 4/5\n",
      "480/480 [==============================] - 34s 71ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0406 - val_accuracy: 0.9906\n",
      "Epoch 5/5\n",
      "480/480 [==============================] - 34s 71ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0354 - val_accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e,\n",
    "                 epochs = 5, validation_split=0.2, \n",
    "                 verbose = 1,\n",
    "                 batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.03477250412106514\n",
      "Test accuracy: 0.9904000163078308\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
